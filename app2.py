# app.py
# Analyse bancaire CSV ‚Äî Workflow 7 √©tapes (Streamlit)
# Auteur : adapt√© pour Jeremy Verhelst ‚Äî robuste CSV FR/EN + cat√©gorisation regex √©ditable
# Python 3.9+

from __future__ import annotations

import io
import re
import json
import base64
import unicodedata
from dataclasses import dataclass
from datetime import datetime
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
import streamlit as st
import altair as alt

# =========================
# --------- CONFIG --------
# =========================
st.set_page_config(
    page_title="Analyse bancaire mensuelle",
    page_icon="üí∂",
    layout="wide"
)

# --------- STYLES / MOBILE -------
HIDE_SIDEBAR_CSS = """
<style>
.block-container {padding-top: 1rem; padding-bottom: 2rem; padding-left: 1rem; padding-right: 1rem;}
.dataframe tbody tr th, .dataframe thead th {font-size: 0.9rem;}
.stButton>button {border-radius: 8px; padding: 0.6rem 1rem; font-weight: 600;}
.stDownloadButton>button {border-radius: 8px; padding: 0.6rem 1rem; font-weight: 600;}
</style>
"""
st.markdown(HIDE_SIDEBAR_CSS, unsafe_allow_html=True)

# =========================
# ----- UTILITAIRES -------
# =========================
def normalize_str(s: str) -> str:
    """Normalise/latinise et compresse les espaces."""
    if not isinstance(s, str):
        s = str(s)
    s = s.strip()
    s = unicodedata.normalize("NFKD", s).encode("ascii", "ignore").decode("ascii")
    s = re.sub(r"\s+", " ", s)
    return s

def try_read_csv(uploaded) -> pd.DataFrame:
    """Lit le CSV en essayant plusieurs couples s√©parateur/encodage."""
    raw = uploaded.read()

    def read_with(params):
        return pd.read_csv(io.BytesIO(raw), **params)

    trials = [
        dict(sep=";", encoding="utf-8", engine="python"),
        dict(sep=",", encoding="utf-8", engine="python"),
        dict(sep="\t", encoding="utf-8", engine="python"),
        dict(sep=";", encoding="latin1", engine="python"),
        dict(sep=",", encoding="latin1", engine="python"),
    ]
    last_err = None
    for p in trials:
        try:
            df = read_with(p)
            return df
        except Exception as e:
            last_err = e
    raise ValueError(f"Impossible de lire le CSV. Derni√®re erreur: {last_err}")

def infer_columns(df: pd.DataFrame) -> Dict[str, Optional[str]]:
    """
    Devine les colonnes cl√©s: date, libell√©, d√©bit, cr√©dit, montant (selon banques/export FR/EN).
    """
    cols = {c.lower().strip(): c for c in df.columns}

    candidates_date   = ["date", "valeur", "date operation", "date_op", "operation date", "transaction date", "date de l'operation"]
    candidates_label  = ["libelle", "libell√©", "label", "description", "motif", "details", "remarque"]
    candidates_debit  = ["debit", "debit (‚Ç¨)", "montant debit", "sortie", "debits"]
    candidates_credit = ["credit", "credit (‚Ç¨)", "montant credit", "entree", "credits"]
    candidates_amount = ["montant", "amount", "valeur (‚Ç¨)", "value", "total", "solde mouvement"]

    def find(cands):
        for c in cands:
            if c in cols:
                return cols[c]
        # fallback partiel
        for k, v in cols.items():
            for c in cands:
                if c in k:
                    return v
        return None

    return {
        "date": find(candidates_date),
        "label": find(candidates_label),
        "debit": find(candidates_debit),
        "credit": find(candidates_credit),
        "amount": find(candidates_amount),
    }

def _to_num(s) -> float:
    """Convertit cha√Æne h√©t√©rog√®ne en float, g√®re formats FR (1 234,56)."""
    if pd.isna(s):
        return np.nan
    if isinstance(s, (int, float)):
        return float(s)
    s = str(s).replace("\u00A0", "").replace(" ", "")
    # Format FR : virgule d√©cimale
    if s.count(",") == 1 and s.count(".") == 0:
        s = s.replace(",", ".")
    s = re.sub(r"[^\d\.\-]", "", s)
    try:
        return float(s)
    except Exception:
        return np.nan

def coerce_amounts(df: pd.DataFrame, amount_col, debit_col, credit_col) -> pd.Series:
    """
    Cr√©e 'amount_signed' (n√©gatif pour sorties, positif pour entr√©es).
    Priorit√© : si 'amount' existe => signe conserv√© ; sinon cr√©dit - d√©bit.
    """
    if amount_col and amount_col in df.columns:
        amt = df[amount_col].map(_to_num)
        if debit_col and credit_col and (debit_col in df.columns) and (credit_col in df.columns):
            # parfois les exports posent signe invers√©: si abs(amt) == debit or credit, on garde amt
            return amt
        return amt

    deb = df[debit_col].map(_to_num).fillna(0.0) if (debit_col and debit_col in df.columns) else 0.0
    cre = df[credit_col].map(_to_num).fillna(0.0) if (credit_col and credit_col in df.columns) else 0.0
    return cre - deb

# =========================
# ----- PATRONS/REGEX -----
# =========================
# Cr√©dit r√©currents (entr√©es) ‚Äî √©ditables dans l'UI
DEFAULT_RECURRING_CREDITS = [
    {"label": "Participation Jeremy",  "amount": 1150.0},
    {"label": "Participation Vanessa", "amount": 1050.0},
    {"label": "Participation Jeremy 2","amount": 530.0},
]

# Fournisseurs / contrats r√©currents (charges fixes) ‚Äî √©ditables
DEFAULT_PROVIDER_PATTERNS = [
    {"Label": "Cr√©dit immobilier",                       "Regex": r"(echeance.*pret|pret|credit|hypothec|immobilier|echeance\s*de\s*credit)"},
    {"Label": "Assurance habitation / BPCE",             "Regex": r"(bpce\s+assurances?|multirisque|habitation)"},
    {"Label": "Assurance GENERALI IARD",                 "Regex": r"(generali\s+iard)"},
    {"Label": "Assurance GENERALI VIE",                  "Regex": r"(generali\s+vie)"},
    {"Label": "Freebox (Internet fixe)",                 "Regex": r"(free\s*telecom|freebox)"},
    {"Label": "Free Mobile",                              "Regex": r"(free\s*mobile)"},
    {"Label": "SFR (fixe/mobile)",                        "Regex": r"\bsfr\b"},
    {"Label": "√âlectricit√© ‚Äî Sowee (EDF)",               "Regex": r"(sowee\s*by\s*edf|sowee)"},
    {"Label": "√âlectricit√© ‚Äî EDF",                        "Regex": r"\bedf\b"},
    {"Label": "√âlectricit√© ‚Äî Bellenergie / EdP",         "Regex": r"(bellenergie|electricit[e√©]\s*de\s*provence)"},
    {"Label": "Eau (SEM / r√©gies)",                       "Regex": r"(soc(i[e√©]t[e√©])?\s*des\s*eaux|eau|veolia|suez|saur)"},
    {"Label": "Abonnements streaming",                    "Regex": r"(netflix|spotify|deezer|prime|canal\+|molotov|youtube\s*premium)"},
    {"Label": "Frais bancaires",                          "Regex": r"(cotis(ations)?\s+bancaires|frais\s+bancaires)"},
]

# Cat√©gories variables ‚Äî patrons longs (√©ditables)
DEFAULT_PATTERN_ALIM = (
    r"(carrefour|leclerc|e\.?leclerc|intermarch[e√©]|super\s*u|u\s?express|u\s*drive|systeme\s?u|"
    r"auchan|lidl|aldi|monoprix|picard|grand\s*frais|biocoop|spar|casino|geant|franprix|"
    r"market|hyper|drive|"
    r"boucherie|charcuterie|boulangerie|patisserie|p[a√¢]tisserie|"
    r"fromagerie|poissonnerie|primeur|mara[i√Æ]cher|"
    r"marche\b|march[e√©]\s+couvert|"
    r"thiriet|votre\s*marche|maxicoffee|"
    r"ubereats|uber\s*eats|deliveroo|just\s*eat|too\s*good\s*to\s*go)"
)
DEFAULT_PATTERN_ANIM = (
    r"(zooplus|bitiba|maxi\s*zoo|truffaut|animalis|botanic|jardiland|wanimo|zoofast|"
    r"ferme\s*des\s*animaux|medicanimal|"
    r"croquette|croquettes|liti[e√®]re|friandises|"
    r"v[e√©]t[e√©]rinaire|veto|clinique\s*v[e√©]t[e√©]rinaire|antipuces|vermifuge|"
    r"royal\s*canin|pro\s*plan|purina|feliway|frontline|advantage|bravecto)"
)
DEFAULT_PATTERN_CARBURANT = (
    r"(total(?:energies)?|esso|bp|shell|avia|repsol|eni|dyneff|as24|cora\s*station|"
    r"leclerc\s*station|e\.?leclerc\s*station|intermarch[e√©]\s*station|carrefour\s*station|"
    r"auchan\s*station|station\s*service|station\s*essence|"
    r"carburant|gasoil|gazole|diesel|sans\s*plomb|sp95|sp98)"
)
DEFAULT_PATTERN_CASH = (
    r"(retrait\s*(?:dab|gab)?|dab\b|gab\b|distributeur|atm|atm\s*withdrawal|withdrawal|"
    r"retrait\s*especes|retrait\s*esp[e√®]ces|\bcash\b)"
)

# =========================
# ----- DATA CLASSES ------
# =========================
@dataclass
class ColumnMap:
    date: Optional[str]
    label: Optional[str]
    debit: Optional[str]
    credit: Optional[str]
    amount: Optional[str]

# =========================
# --------- UI ------------
# =========================
st.title("Analyse bancaire CSV ‚Äî Workflow 7 √©tapes")
st.caption("Charge un relev√© CSV, cat√©gorise automatiquement, puis visualise & exporte.")

with st.expander("‚ÑπÔ∏è Comment pr√©parer le CSV ?", expanded=False):
    st.markdown(
        "- Export natif de ta banque (CSV, s√©parateur `;`, `,` ou `\\t`).\n"
        "- Encodage UTF‚Äë8 ou Latin‚Äë1 support√©.\n"
        "- Colonnes attendues (si dispo) : **date**, **libell√©**, **d√©bit**, **cr√©dit**, **montant**."
    )

uploaded = st.file_uploader("D√©pose ton fichier CSV", type=["csv"])

# Param√®tres (√©ditables)
colA, colB = st.columns([1, 1])
with colA:
    st.subheader("‚öôÔ∏è Patrons fournisseurs (fixes)")
    providers_json = st.text_area(
        "Liste JSON de fournisseurs (Label/Regex)",
        value=json.dumps(DEFAULT_PROVIDER_PATTERNS, ensure_ascii=False, indent=2),
        height=220
    )
with colB:
    st.subheader("‚öôÔ∏è Cr√©dits r√©currents (entr√©es fixes)")
    credits_json = st.text_area(
        "Liste JSON de cr√©dits (label/amount)",
        value=json.dumps(DEFAULT_RECURRING_CREDITS, ensure_ascii=False, indent=2),
        height=220
    )

st.subheader("‚öôÔ∏è Cat√©gories variables (Regex, une par ligne)")
col1, col2, col3 = st.columns(3)
with col1:
    pat_alim = st.text_area("Alimentation / Hypermarch√©s", value=DEFAULT_PATTERN_ALIM, height=150)
with col2:
    pat_anim = st.text_area("Animaux", value=DEFAULT_PATTERN_ANIM, height=150)
with col3:
    pat_carb = st.text_area("Carburant / Stations", value=DEFAULT_PATTERN_CARBURANT, height=150)

pat_cash = st.text_area("Retraits esp√®ces (DAB/ATM)", value=DEFAULT_PATTERN_CASH, height=100)

# =========================
# --- WORKFLOW (7 √©tapes) -
# =========================
if uploaded is not None:
    # 1) Lecture robuste
    df_raw = try_read_csv(uploaded)

    # 2) Normalisation des noms + inf√©rence de colonnes
    colmap_dict = infer_columns(df_raw)
    cmap = ColumnMap(**colmap_dict)

    # 3) Pr√©paration DataFrame standard
    df = df_raw.copy()
    # libell√©
    if cmap.label and cmap.label in df.columns:
        df["label"] = df[cmap.label].astype(str).map(normalize_str).str.lower()
    else:
        df["label"] = ""

    # date
    if cmap.date and cmap.date in df.columns:
        df["date"] = pd.to_datetime(df[cmap.date], errors="coerce", dayfirst=True, infer_datetime_format=True)
    else:
        # fallback : aucune date => NaT
        df["date"] = pd.NaT

    # 4) Montants sign√©s
    df["amount_signed"] = coerce_amounts(df, cmap.amount, cmap.debit, cmap.credit).fillna(0.0)
    df["year"] = df["date"].dt.year
    df["month"] = df["date"].dt.to_period("M").astype(str)

    # 5) Cat√©gorisation automatique
    def label_matches(pat: str, text: str) -> bool:
        try:
            return re.search(pat, text or "", flags=re.IGNORECASE) is not None
        except re.error:
            return False

    # Cat√©gorie par d√©faut
    df["category"] = "Autres"

    # Variables
    df.loc[df["label"].apply(lambda x: label_matches(pat_alim, x)), "category"] = "Alimentation"
    df.loc[df["label"].apply(lambda x: label_matches(pat_anim, x)), "category"] = "Animaux"
    df.loc[df["label"].apply(lambda x: label_matches(pat_carb, x)), "category"] = "Carburant"
    df.loc[df["label"].apply(lambda x: label_matches(pat_cash, x)), "category"] = "Retraits/Especes"

    # Fixes via providers
    try:
        providers = json.loads(providers_json)
        for p in providers:
            lab, rgx = p.get("Label"), p.get("Regex")
            if lab and rgx:
                df.loc[df["label"].apply(lambda x: label_matches(rgx, x)), "category"] = lab
    except Exception as e:
        st.warning(f"Impossible de parser les fournisseurs : {e}")

    # 6) Ajout des cr√©dits r√©currents (en tant que lignes synth√©tiques optionnelles)
    add_fixed = st.checkbox("Ajouter les cr√©dits r√©currents mensuels au budget (lignes synth√©tiques)", value=True)
    synth_rows = []
    if add_fixed:
        try:
            rec_credits = json.loads(credits_json)
            # On ajoute pour le mois visible (ou tous les mois pr√©sents)
            months_present = sorted(df["month"].dropna().unique().tolist())
            target_months = months_present or [datetime.now().strftime("%Y-%m")]
            for m in target_months:
                for c in rec_credits:
                    synth_rows.append(
                        dict(date=pd.Period(m).to_timestamp(how="start"),
                             label=normalize_str(c.get("label", "")),
                             amount_signed=float(c.get("amount", 0.0)),
                             year=int(m.split("-")[0]),
                             month=m,
                             category="Cr√©dits fixes")
                    )
        except Exception as e:
            st.warning(f"Impossible de parser les cr√©dits r√©currents : {e}")

    if synth_rows:
        df = pd.concat([df, pd.DataFrame(synth_rows)], ignore_index=True)

    # 7) Tableaux, filtres, graphiques, export
    st.divider()
    st.subheader("üìä Filtres")
    colf1, colf2, colf3 = st.columns(3)
    with colf1:
        years = ["(Tous)"] + [str(y) for y in sorted(df["year"].dropna().unique())]
        ypick = st.selectbox("Ann√©e", options=years, index=0)
    with colf2:
        months_all = ["(Tous)"] + sorted(df["month"].dropna().unique().tolist())
        mpick = st.selectbox("Mois (AAAA-MM)", options=months_all, index=0)
    with colf3:
        cats_all = ["(Toutes)"] + sorted(df["category"].dropna().unique().tolist())
        cpick = st.selectbox("Cat√©gorie", options=cats_all, index=0)

    dfv = df.copy()
    if ypick != "(Tous)":
        dfv = dfv[dfv["year"] == int(ypick)]
    if mpick != "(Tous)":
        dfv = dfv[dfv["month"] == mpick]
    if cpick != "(Toutes)":
        dfv = dfv[dfv["category"] == cpick]

    st.subheader("üßæ Transactions (apr√®s cat√©gorisation)")
    st.dataframe(
        dfv.sort_values(["date"], ascending=[False])[["date", "label", "category", "amount_signed"]],
        use_container_width=True,
        height=340
    )

    # Agr√©gations
    st.subheader("üìà Synth√®se par mois et par cat√©gorie")
    g_month = dfv.groupby("month", dropna=True)["amount_signed"].sum().reset_index()
    g_cat   = dfv.groupby("category", dropna=True)["amount_signed"].sum().reset_index()

    colm, colc = st.columns(2)
    with colm:
        st.markdown("**Solde par mois** (positif = plus d'entr√©es que de sorties)")
        chart_m = alt.Chart(g_month).mark_bar(color="#2C7BE5").encode(
            x=alt.X("month:O", title="Mois"),
            y=alt.Y("amount_signed:Q", title="Solde (‚Ç¨)"),
            tooltip=["month", alt.Tooltip("amount_signed:Q", title="Solde", format=",.2f")]
        )
        st.altair_chart(chart_m.properties(height=300), use_container_width=True)
        st.metric("Solde total (p√©riode filtr√©e)", f"{g_month['amount_signed'].sum():,.2f} ‚Ç¨".replace(",", " "))

    with colc:
        st.markdown("**D√©penses/recettes par cat√©gorie**")
        chart_c = alt.Chart(g_cat).mark_bar().encode(
            x=alt.X("category:N", sort="-y", title="Cat√©gorie"),
            y=alt.Y("amount_signed:Q", title="Montant (‚Ç¨)"),
            color=alt.condition(
                alt.datum.amount_signed < 0,
                alt.value("#E63757"),  # d√©penses
                alt.value("#00D97E")   # entr√©es
            ),
            tooltip=[alt.Tooltip("category:N", title="Cat√©gorie"), alt.Tooltip("amount_signed:Q", title="Montant", format=",.2f")]
        )
        st.altair_chart(chart_c.properties(height=300), use_container_width=True)

    # Export XLSX / CSV du jeu filtr√© + mapping colonnes
    st.subheader("üì§ Export")
    def to_csv_bytes(df_: pd.DataFrame) -> bytes:
        return df_.to_csv(index=False).encode("utf-8")

    export_cols = ["date", "label", "category", "amount_signed", "year", "month"]
    csv_bytes = to_csv_bytes(dfv[export_cols])

    st.download_button(
        "‚¨áÔ∏è T√©l√©charger CSV (filtr√©)",
        data=csv_bytes,
        file_name=f"banque_filtre_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
        mime="text/csv"
    )

    # Rappel colonnes d√©tect√©es
    with st.expander("üß© Colonnes d√©tect√©es / mapping", expanded=False):
        st.json(colmap_dict, expanded=True)

else:
    st.info("D√©pose ton CSV pour d√©marrer l‚Äôanalyse.")
